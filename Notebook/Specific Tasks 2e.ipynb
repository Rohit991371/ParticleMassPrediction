{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efca5c8-5637-4730-bc20-9d4cd0588e49",
      "metadata": {
        "id": "5efca5c8-5637-4730-bc20-9d4cd0588e49"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import pyarrow.parquet as pq\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9fb1b6f-c232-4768-b681-c094c36315d4",
      "metadata": {
        "id": "c9fb1b6f-c232-4768-b681-c094c36315d4"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nXM5haE4zhm1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXM5haE4zhm1",
        "outputId": "8ff5f701-f5ec-4cea-82bb-e38ced3313ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8LHf0SBvqrt3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LHf0SBvqrt3",
        "outputId": "6b5840d0-ac97-4f1c-dabc-6963ae677c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory growth enabled for GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "# tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
        "\n",
        "# Check if any GPUs are available before attempting to access them\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Set memory growth for the first GPU\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    print(\"Memory growth enabled for GPU:\", gpus[0])\n",
        "else:\n",
        "    print(\"No GPUs available. Running on CPU instead.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pUfu6hqBVFUM",
      "metadata": {
        "id": "pUfu6hqBVFUM"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade \"dask[complete]==2024.12.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a0d6d2-472e-4860-a6a9-daf57c97a7c7",
      "metadata": {
        "id": "36a0d6d2-472e-4860-a6a9-daf57c97a7c7"
      },
      "outputs": [],
      "source": [
        "import cudf\n",
        "import dask_cudf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9PCPjPl286",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b9PCPjPl286",
        "outputId": "5fcf2d79-7a5b-40c0-cec8-75d8b74485ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B3TMpQs2ry7z",
      "metadata": {
        "id": "B3TMpQs2ry7z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PyOSDFs3r0b4",
      "metadata": {
        "id": "PyOSDFs3r0b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6rxZYeDYig9q",
      "metadata": {
        "id": "6rxZYeDYig9q"
      },
      "outputs": [],
      "source": [
        "# import dask.dataframe as dd\n",
        "\n",
        "# # Correct file path\n",
        "# file_path = \"/content/drive/MyDrive/Colab Notebooks/top_gun_opendata_3.parquet\"\n",
        "\n",
        "# # Load dataset\n",
        "# df = dd.read_parquet(file_path, engine=\"pyarrow\")\n",
        "\n",
        "# # Display dataset info\n",
        "# print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JC9h4niEuDWa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC9h4niEuDWa",
        "outputId": "f08840f2-0e6a-49f2-b7e5-5b96eb6ac5a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame partitions: 150448\n",
            "DataFrame columns: Index(['X_jet', 'm', 'iphi', 'pt', 'ieta'], dtype='object')\n",
            "DataFrame dtypes: X_jet     object\n",
            "m        float64\n",
            "iphi     float64\n",
            "pt       float64\n",
            "ieta     float64\n",
            "dtype: object\n",
            "Sample from first partition:\n",
            "                                               X_jet           m  iphi  \\\n",
            "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  232.846863  66.0   \n",
            "\n",
            "           pt  ieta  \n",
            "0  865.297302  26.0  \n"
          ]
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import dask\n",
        "\n",
        "# Set Dask configuration to limit memory usage\n",
        "dask.config.set({\"dataframe.shuffle.method\": \"disk\"})\n",
        "dask.config.set({\"distributed.worker.memory.target\": 0.7})  # Use 60% of available memory\n",
        "dask.config.set({\"distributed.worker.memory.spill\": 0.8})   # Spill to disk at 70% memory\n",
        "\n",
        "# Load dataset with optimized parameters\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/top_gun_opendata_3.parquet\"\n",
        "df = dd.read_parquet(\n",
        "    file_path,\n",
        "    engine=\"pyarrow\",\n",
        "    blocksize=\"64MB\",\n",
        "    split_row_groups=True   # Split row groups for better parallelization\n",
        ")\n",
        "\n",
        "# Display dataset info WITHOUT computing (important!)\n",
        "print(\"DataFrame partitions:\", df.npartitions)\n",
        "print(\"DataFrame columns:\", df.columns)\n",
        "print(\"DataFrame dtypes:\", df.dtypes)\n",
        "\n",
        "\n",
        "# Instead of df.head() which computes, use:\n",
        "sample = df.partitions[0].compute()  # Only compute the first partition\n",
        "print(\"Sample from first partition:\")\n",
        "print(sample.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pfHjRt9yyEc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "collapsed": true,
        "id": "pfHjRt9yyEc7",
        "outputId": "d5d20ddd-4917-4868-e1f1-ab314d89bd9a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"X_jet\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 232.84686279296875,\n        \"max\": 232.84686279296875,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          232.84686279296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 66.0,\n        \"max\": 66.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          66.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 865.2973022460938,\n        \"max\": 865.2973022460938,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          865.2973022460938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ieta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 26.0,\n        \"max\": 26.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          26.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-60a572b5-9dea-4d37-a71a-3374e65a0f07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_jet</th>\n",
              "      <th>m</th>\n",
              "      <th>iphi</th>\n",
              "      <th>pt</th>\n",
              "      <th>ieta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>232.846863</td>\n",
              "      <td>66.0</td>\n",
              "      <td>865.297302</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60a572b5-9dea-4d37-a71a-3374e65a0f07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60a572b5-9dea-4d37-a71a-3374e65a0f07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60a572b5-9dea-4d37-a71a-3374e65a0f07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               X_jet           m  iphi  \\\n",
              "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  232.846863  66.0   \n",
              "\n",
              "           pt  ieta  \n",
              "0  865.297302  26.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.partitions[0].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5-2zXxRMAU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ed5-2zXxRMAU",
        "outputId": "6733860e-e530-4812-9418-767320651bc4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"X_jet\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 465.12054443359375,\n        \"max\": 465.12054443359375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          465.12054443359375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iphi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 11.0,\n        \"max\": 11.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 616.8911743164062,\n        \"max\": 616.8911743164062,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          616.8911743164062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ieta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 17.0,\n        \"max\": 17.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-118ff828-e780-448a-b804-dd60f97be2c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_jet</th>\n",
              "      <th>m</th>\n",
              "      <th>iphi</th>\n",
              "      <th>pt</th>\n",
              "      <th>ieta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>465.120544</td>\n",
              "      <td>11.0</td>\n",
              "      <td>616.891174</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-118ff828-e780-448a-b804-dd60f97be2c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-118ff828-e780-448a-b804-dd60f97be2c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-118ff828-e780-448a-b804-dd60f97be2c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               X_jet           m  iphi  \\\n",
              "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  465.120544  11.0   \n",
              "\n",
              "           pt  ieta  \n",
              "0  616.891174  17.0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.partitions[5].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TN65ErFVurf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN65ErFVurf0",
        "outputId": "6cf8a5b7-ed10-44b2-fa5c-9b8e23bdadab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['X_jet', 'm', 'iphi', 'pt', 'ieta'], dtype='object')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd15429-bf8b-4921-9918-6bef22f4378c",
      "metadata": {
        "id": "0bd15429-bf8b-4921-9918-6bef22f4378c"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    # Extract target variable (particle mass)\n",
        "    y = df['m'].values\n",
        "\n",
        "    # Extract image features (X_jet with the required channels)\n",
        "    # Assum X_jet contains the channels in this order: [Track pT, DZ, D0, ECAL]\n",
        "    # used all channels as mentioned in the requirements (at least ECAL and Track pT)\n",
        "\n",
        "    x_jet_columns = [col for col in df.columns if 'X_jet' in col]\n",
        "\n",
        "    print(f\"Number of X_jet columns: {len(x_jet_columns)}\")\n",
        "    print(f\"Sample X_jet column names: {x_jet_columns[:5] if len(x_jet_columns) >= 5 else x_jet_columns}\")\n",
        "\n",
        "    # Reshape the data based on ieta, iphi dimensions and channels\n",
        "    # Assuming the data structure follows the 125x125 matrix with ieta, iphi coordinates\n",
        "\n",
        "    # Get unique ieta and iphi values to determine dimensions\n",
        "    if 'ieta' in df.columns and 'iphi' in df.columns:\n",
        "        ieta_dim = len(df['ieta'].unique())\n",
        "        iphi_dim = len(df['iphi'].unique())\n",
        "        print(f\"Detected dimensions: ieta={ieta_dim}, iphi={iphi_dim}\")\n",
        "    else:\n",
        "        # Default to the mentioned 125x125 if coordinates are not explicitly in columns\n",
        "        ieta_dim, iphi_dim = 125, 125\n",
        "        print(f\"Using default dimensions: ieta={ieta_dim}, iphi={iphi_dim}\")\n",
        "\n",
        "    # Extract X_jet data and reshape\n",
        "    try:\n",
        "        # Approach 1: If X_jet is stored as separate columns for each channel and position\n",
        "        if len(x_jet_columns) >= ieta_dim * iphi_dim * 4:  \n",
        "            X = np.zeros((len(df), ieta_dim, iphi_dim, 4))\n",
        "\n",
        "            # Logic to reshape data from flat columns to 4D tensor\n",
        "            # This is a placeholder and needs to be adapted to  specific data format\n",
        "            print(\"Reshaping data from columns to 4D tensor...\")\n",
        "\n",
        "        # Approach 2: If X_jet is already stored as a 4D tensor or can be easily reshaped\n",
        "        elif 'X_jet' in df.columns and isinstance(df['X_jet'].iloc[0], (np.ndarray, list)):\n",
        "            X = np.stack(df['X_jet'].values)\n",
        "            print(f\"Loaded X_jet as a tensor with shape: {X.shape}\")\n",
        "\n",
        "        else:\n",
        "            # Another approach: If data is stored differently, adapt accordingly\n",
        "            print(\"Data format not recognized. Please adapt the preprocessing code.\")\n",
        "            # Placeholder for demonstration\n",
        "            X = np.random.rand(len(df), ieta_dim, iphi_dim, 4)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data reshaping: {e}\")\n",
        "        print(\"Creating a placeholder tensor for demonstration purposes.\")\n",
        "        X = np.random.rand(len(df), ieta_dim, iphi_dim, 4)\n",
        "\n",
        "    # Normalize the data\n",
        "    # For each channel separately\n",
        "    for i in range(X.shape[3]):\n",
        "        channel_data = X[:, :, :, i]\n",
        "        mean = np.mean(channel_data)\n",
        "        std = np.std(channel_data)\n",
        "        X[:, :, :, i] = (channel_data - mean) / (std + 1e-10)  # Add small epsilon to avoid division by zero\n",
        "\n",
        "    print(f\"Processed data shape: X={X.shape}, y={y.shape}\")\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T9AXVv1XZ4VP",
      "metadata": {
        "id": "T9AXVv1XZ4VP"
      },
      "outputs": [],
      "source": [
        "# preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24636780-5a78-433c-8f08-7e34f705dacc",
      "metadata": {
        "id": "24636780-5a78-433c-8f08-7e34f705dacc"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model(input_shape, use_efficient_net=True):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    if use_efficient_net:\n",
        "        # Use EfficientNetB0 as base model (without top layers)\n",
        "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "        # Make base model trainable\n",
        "        base_model.trainable = True\n",
        "\n",
        "        # If input has 4 channels but EfficientNet expects 3, adapt accordingly\n",
        "        if input_shape[2] != 3:\n",
        "            # Add a 1x1 convolution to adapt the number of channels\n",
        "            x = layers.Conv2D(3, (1, 1), padding='same')(inputs)\n",
        "            x = base_model(x)\n",
        "        else:\n",
        "            x = base_model(inputs)\n",
        "\n",
        "        # Add pooling\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    else:\n",
        "        # Custom CNN architecture\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Regression head\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Output layer (no activation for regression)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01e9e28-fbe1-458a-819f-a3f3b328fef7",
      "metadata": {
        "id": "e01e9e28-fbe1-458a-819f-a3f3b328fef7"
      },
      "outputs": [],
      "source": [
        "def compile_and_train(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=15):\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.0001\n",
        "    )\n",
        "\n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=5,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c5fc7a-534a-47b0-ab14-f069267dc163",
      "metadata": {
        "id": "17c5fc7a-534a-47b0-ab14-f069267dc163"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Test Mean Absolute Error: {mae:.4f}\")\n",
        "    print(f\"Test R² Score: {r2:.4f}\")\n",
        "\n",
        "    # Plot predictions vs actual\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
        "    plt.xlabel('Actual Mass')\n",
        "    plt.ylabel('Predicted Mass')\n",
        "    plt.title('Predicted vs Actual Particle Mass')\n",
        "    plt.savefig('pred_vs_actual.png')\n",
        "\n",
        "    return mae, r2, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BpaTUS81UJqf",
      "metadata": {
        "id": "BpaTUS81UJqf"
      },
      "outputs": [],
      "source": [
        "# !pip install dask_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gyDE-3AvTDR3",
      "metadata": {
        "id": "gyDE-3AvTDR3"
      },
      "outputs": [],
      "source": [
        "from dask_ml.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd4c5e3-38ea-4dad-8aaf-cf8c7903d401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd4c5e3-38ea-4dad-8aaf-cf8c7903d401",
        "outputId": "517aa282-84af-44f7-e992-9f2427f957ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available: 1\n",
            "Using Dask-cuDF for GPU acceleration\n",
            "Loading dataset from /content/drive/MyDrive/Colab Notebooks/top_gun_opendata_3.parquet...\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check for GPU and enable memory growth\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Try using Dask-cuDF for GPU acceleration\n",
        "try:\n",
        "    import cudf\n",
        "    import dask_cudf\n",
        "    use_gpu = True\n",
        "    print(\"Using Dask-cuDF for GPU acceleration\")\n",
        "except ImportError:\n",
        "    use_gpu = False\n",
        "    print(\"Using CPU-based Dask\")\n",
        "\n",
        "def load_data(file_path):\n",
        "    return dd.read_parquet(\n",
        "        file_path,\n",
        "        engine=\"pyarrow\",\n",
        "        blocksize=\"256MB\",\n",
        "        split_row_groups=True\n",
        "    )\n",
        "\n",
        "def main():\n",
        "    file_path = \"/content/drive/MyDrive/Colab Notebooks/top_gun_opendata_3.parquet\"\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading dataset from {file_path}...\")\n",
        "    df = load_data(file_path)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    # Compute number of rows efficiently\n",
        "    num_samples = df.shape[0].compute()\n",
        "    print(f\"Number of samples: {num_samples}\")\n",
        "    print(f\"Columns: {df.columns.tolist()[:10]} ...\")\n",
        "\n",
        "    # Estimate missing values using 10% of the data\n",
        "    sample_df = df.sample(frac=0.1, random_state=42)\n",
        "    approx_missing_values = sample_df.isnull().sum().compute().sum() * 10\n",
        "    print(f\"Approximate Missing Values: {approx_missing_values}\")\n",
        "\n",
        "    # Extract features and target\n",
        "    X, y = preprocess_data(df)\n",
        "\n",
        "    # Split the data into train and test sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "    # Further split train set into training and validation (80% train, 20% validation)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "    # Convert Dask objects to NumPy/Pandas\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = dask.compute(X_train, X_val, X_test, y_train, y_val, y_test)\n",
        "\n",
        "    # Compute dataset sizes correctly\n",
        "    train_samples, val_samples, test_samples = X_train.shape[0], X_val.shape[0], X_test.shape[0]\n",
        "    total_samples = train_samples + val_samples + test_samples\n",
        "\n",
        "    print(f\"Training: {train_samples} samples ({train_samples / total_samples:.1%})\")\n",
        "    print(f\"Validation: {val_samples} samples ({val_samples / total_samples:.1%})\")\n",
        "    print(f\"Test: {test_samples} samples ({test_samples / total_samples:.1%})\")\n",
        "\n",
        "    # Build model\n",
        "    input_shape = X_train.shape[1:]\n",
        "    print(f\"\\nInput shape: {input_shape}\")\n",
        "\n",
        "    use_efficient_net = True  # Set to False to use custom CNN\n",
        "    model = build_cnn_model(input_shape, use_efficient_net=use_efficient_net)\n",
        "    model.summary()\n",
        "\n",
        "    # Train model using GPU\n",
        "    with tf.device('/GPU:0'):\n",
        "        model, history = compile_and_train(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['mae'])\n",
        "    plt.plot(history.history['val_mae'])\n",
        "    plt.title('Model MAE')\n",
        "    plt.ylabel('MAE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "\n",
        "    # Evaluate model\n",
        "    mae, r2, y_pred = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('particle_mass_regression_model.h5')\n",
        "    print(\"Model saved as 'particle_mass_regression_model.h5'\")\n",
        "\n",
        "    return {\n",
        "        'mae': mae,\n",
        "        'r2': r2,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e0db52-bcc5-4e89-a881-a847ef72af6b",
      "metadata": {
        "id": "e3e0db52-bcc5-4e89-a881-a847ef72af6b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43cfcec-46ef-4923-91f2-c0fadc75ac64",
      "metadata": {
        "id": "b43cfcec-46ef-4923-91f2-c0fadc75ac64"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5869c55-0d27-40e3-aa3e-944f9d5e3e96",
      "metadata": {
        "id": "a5869c55-0d27-40e3-aa3e-944f9d5e3e96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a0e954-7008-4f1c-bed6-b72588731f9e",
      "metadata": {
        "id": "a1a0e954-7008-4f1c-bed6-b72588731f9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "117b2b64-bd76-4fff-b1ea-c919d7f1968d",
      "metadata": {
        "id": "117b2b64-bd76-4fff-b1ea-c919d7f1968d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bccce6-8651-45e7-a987-4e9dd69c84c2",
      "metadata": {
        "id": "78bccce6-8651-45e7-a987-4e9dd69c84c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0b7c8a-791f-41b4-8836-f7f0ebb5c98a",
      "metadata": {
        "id": "8c0b7c8a-791f-41b4-8836-f7f0ebb5c98a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b6b2ea6-13a6-4429-a06f-4dbb08dca93d",
      "metadata": {
        "id": "2b6b2ea6-13a6-4429-a06f-4dbb08dca93d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a57f2f-2cba-4992-9fe3-620947b5f2b1",
      "metadata": {
        "id": "d9a57f2f-2cba-4992-9fe3-620947b5f2b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6293d8bb-0cbe-4959-8bdb-2192a15f6dad",
      "metadata": {
        "id": "6293d8bb-0cbe-4959-8bdb-2192a15f6dad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b835aa-a78f-4ed6-b397-b88574923371",
      "metadata": {
        "id": "77b835aa-a78f-4ed6-b397-b88574923371"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10c382d-bf21-4f8d-934c-1fac1885dd63",
      "metadata": {
        "id": "a10c382d-bf21-4f8d-934c-1fac1885dd63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c1acd9-11e1-4261-a03d-27fba92a7a3d",
      "metadata": {
        "id": "42c1acd9-11e1-4261-a03d-27fba92a7a3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce822b1d-4c90-484f-b0f7-4b89123cb96a",
      "metadata": {
        "id": "ce822b1d-4c90-484f-b0f7-4b89123cb96a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b14ada-fe14-426b-8fe4-f549498ac350",
      "metadata": {
        "id": "12b14ada-fe14-426b-8fe4-f549498ac350"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21f6c9e-c89c-4438-b7a2-4a17488ffa38",
      "metadata": {
        "id": "e21f6c9e-c89c-4438-b7a2-4a17488ffa38"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288caf75-fa34-4cbb-ab28-170e785cd1fa",
      "metadata": {
        "id": "288caf75-fa34-4cbb-ab28-170e785cd1fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ba1397-0450-4d7d-89d9-e3cf8bd88720",
      "metadata": {
        "id": "b0ba1397-0450-4d7d-89d9-e3cf8bd88720"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34c452ae-c36f-402d-be9d-b348fc1b04bc",
      "metadata": {
        "id": "34c452ae-c36f-402d-be9d-b348fc1b04bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9582979b-cc0c-487c-b461-810ee307e36c",
      "metadata": {
        "id": "9582979b-cc0c-487c-b461-810ee307e36c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "752544b3-0557-44db-84ad-b0935c59a33e",
      "metadata": {
        "id": "752544b3-0557-44db-84ad-b0935c59a33e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43026383-8b16-43da-81cb-b02c35a35d5b",
      "metadata": {
        "id": "43026383-8b16-43da-81cb-b02c35a35d5b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
